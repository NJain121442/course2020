{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c080510f18f346e8bb1b3d87628d3efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_463b84e7d4a64a5cad0fc5700783dfd3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b4ebd39fb7d4df983e96de6276d2fa1",
              "IPY_MODEL_8c3d95f913cb4d8cbf193d345abd7179"
            ]
          }
        },
        "463b84e7d4a64a5cad0fc5700783dfd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b4ebd39fb7d4df983e96de6276d2fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d568cb66a1a345458fda454680246202",
            "_dom_classes": [],
            "description": " 16%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fefa7a29a0104b6c948c692e97abcf9d"
          }
        },
        "8c3d95f913cb4d8cbf193d345abd7179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1028d4ae22a14fa8bfd9d4287f83a326",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/100 [20:37&lt;2:13:31, 95.37s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aad1667e86904bf1b61dd69afffbbe10"
          }
        },
        "d568cb66a1a345458fda454680246202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fefa7a29a0104b6c948c692e97abcf9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1028d4ae22a14fa8bfd9d4287f83a326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aad1667e86904bf1b61dd69afffbbe10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NJain121442/course2020/blob/master/16August_SEM_Conv2d_V2_w/o_FC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKSmgXNT75Kt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "83d735de-e885-4e7d-b207-3621e8ed2197"
      },
      "source": [
        "!pip install kornia\n",
        "from kornia import filters\n",
        "import torch.nn as nn\n",
        "import glob\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.display import clear_output\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from torchsummary import summary \n",
        "import matplotlib.image as mpimg\n",
        "import torchvision\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kornia in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from kornia) (1.18.5)\n",
            "Requirement already satisfied: torch<1.7.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from kornia) (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.7.0,>=1.6.0->kornia) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Ld9pHHC31n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a930ac45-0bdc-4880-baf8-66c451b0dc53"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6krlmPnxVdHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data_path = \"/content/Fruits/\"\n",
        "#Data_path = \"/content/drive/My Drive/AutoEncoder_training/AutoEncoder_training/\"\n",
        "Data_path = \"/content/drive/My Drive/All_class_images\""
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u_2M6dAdOyN",
        "colab_type": "text"
      },
      "source": [
        "Lets Resize all images to same size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-mNUe39uG6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,path,new_size = 226):\n",
        "    #self.filelist = glob.glob(path+'/*.jfif')\n",
        "    self.filelist = glob.glob(path+'/*.tiff')\n",
        "    self.new_size = new_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.filelist)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    temp_filepath = self.filelist[idx]\n",
        "    temp_image = cv2.imread(temp_filepath)\n",
        "    temp_image = cv2.cvtColor(temp_image, cv2.COLOR_BGR2GRAY)\n",
        "    temp_image = temp_image/255\n",
        "    temp_image = torch.Tensor(temp_image)\n",
        "    temp_image = temp_image.unsqueeze(0)\n",
        "    return temp_image"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXkStG8WkAbq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89650afd-fe48-49da-c46d-6ed4b5865462"
      },
      "source": [
        "Data = CustomDataset(Data_path)\n",
        "Data[2].shape"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 504, 504])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lVkLFZfJTpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class COV2D_AutoEncoder(nn.Module):\n",
        "    def __init__(self,filters = [64,128,256,512]):\n",
        "        super(COV2D_AutoEncoder,self).__init__()\n",
        "        self.enc1 = nn.Conv2d(1,filters[0],kernel_size=3,stride=3)\n",
        "        self.enc2 = nn.Conv2d(filters[0],filters[1],kernel_size=3,stride=3)\n",
        "        self.enc3 = nn.Conv2d(filters[1],filters[2],kernel_size=2,stride=3)\n",
        "        self.enc4 = nn.Conv2d(filters[2],filters[3],kernel_size=3,stride=2)\n",
        "        self.pool = nn.MaxPool2d(2,2,return_indices=True)\n",
        "        self.dec1 = nn.ConvTranspose2d(filters[3],filters[2],kernel_size=3,stride=2)\n",
        "        self.dec2 = nn.ConvTranspose2d(filters[2],filters[1], kernel_size=2, stride=3)  \n",
        "        self.dec3 = nn.ConvTranspose2d(filters[1],filters[0], kernel_size=3, stride=3)\n",
        "        self.dec4 = nn.ConvTranspose2d(filters[0] ,1, kernel_size=3, stride=3)\n",
        "        self.unpool = nn.MaxUnpool2d(2,2,padding=0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.enc1(x)) # output will be 168x168x64\n",
        "        x,indices1 = self.pool(x) #output will be 84x84x64\n",
        "        x= F.relu(self.enc2(x)) #output will be 28x28x128\n",
        "        x,indices2 = self.pool(x)   # output will be 14x14x128\n",
        "        x= F.relu(self.enc3(x)) #output will be 5x5x256\n",
        "        x= F.relu(self.enc4(x)) #output will be 2x2x512\n",
        "        Encoded_rep,indices3 = self.pool(x)   # output will be 1x1x512\n",
        "        x = self.unpool(Encoded_rep,indices3)   # output will be 2x2x512\n",
        "        x = F.relu(self.dec1(x)) # ouput will be 5x5x256\n",
        "        x = F.relu(self.dec2(x)) # output will be 14x14x128\n",
        "        x = self.unpool(x,indices2) #output will be 28x28x128\n",
        "        x = F.relu(self.dec3(x)) # output will be 84x84x64\n",
        "        x = self.unpool(x,indices1) #output will be 28x28x128\n",
        "        x = torch.sigmoid(self.dec4(x)) # output will be 504x504x1\n",
        "        return x,Encoded_rep.view(-1,512)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaMlwOS5oEI2",
        "colab_type": "text"
      },
      "source": [
        "**Lets write the first Auto encoder **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q38XOqy27ViA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "5c50bfdd-eacb-4d62-e932-109808e088ca"
      },
      "source": [
        "net = COV2D_AutoEncoder()\n",
        "print(net)\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "summary(net,input_size=(1,504,504),batch_size=1)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COV2D_AutoEncoder(\n",
            "  (enc1): Conv2d(1, 64, kernel_size=(3, 3), stride=(3, 3))\n",
            "  (enc2): Conv2d(64, 128, kernel_size=(3, 3), stride=(3, 3))\n",
            "  (enc3): Conv2d(128, 256, kernel_size=(2, 2), stride=(3, 3))\n",
            "  (enc4): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dec1): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (dec2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(3, 3))\n",
            "  (dec3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(3, 3))\n",
            "  (dec4): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(3, 3))\n",
            "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [1, 64, 168, 168]             640\n",
            "         MaxPool2d-2  [[-1, 64, 84, 84], [-1, 64, 84, 84]]               0\n",
            "            Conv2d-3           [1, 128, 28, 28]          73,856\n",
            "         MaxPool2d-4  [[-1, 128, 14, 14], [-1, 128, 14, 14]]               0\n",
            "            Conv2d-5             [1, 256, 5, 5]         131,328\n",
            "            Conv2d-6             [1, 512, 2, 2]       1,180,160\n",
            "         MaxPool2d-7  [[-1, 512, 1, 1], [-1, 512, 1, 1]]               0\n",
            "       MaxUnpool2d-8             [1, 512, 2, 2]               0\n",
            "   ConvTranspose2d-9             [1, 256, 5, 5]       1,179,904\n",
            "  ConvTranspose2d-10           [1, 128, 14, 14]         131,200\n",
            "      MaxUnpool2d-11           [1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-12            [1, 64, 84, 84]          73,792\n",
            "      MaxUnpool2d-13          [1, 64, 168, 168]               0\n",
            "  ConvTranspose2d-14           [1, 1, 504, 504]             577\n",
            "================================================================\n",
            "Total params: 2,771,457\n",
            "Trainable params: 2,771,457\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.97\n",
            "Forward/backward pass size (MB): 1560686.80\n",
            "Params size (MB): 10.57\n",
            "Estimated Total Size (MB): 1560698.34\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iGHRxfswour",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(Data,batch_size=1)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exgsyM0UKOB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "loss_func = nn.MSELoss()\n",
        "#loss_func = nn.L1Loss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001) \n",
        "#scheduler = ReduceLROnPlateau(optimizer, 'min')\n"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUWlp2R-bYP9",
        "colab_type": "text"
      },
      "source": [
        "Training the Auto encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcg-ESdIwSvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967,
          "referenced_widgets": [
            "c080510f18f346e8bb1b3d87628d3efa",
            "463b84e7d4a64a5cad0fc5700783dfd3",
            "9b4ebd39fb7d4df983e96de6276d2fa1",
            "8c3d95f913cb4d8cbf193d345abd7179",
            "d568cb66a1a345458fda454680246202",
            "fefa7a29a0104b6c948c692e97abcf9d",
            "1028d4ae22a14fa8bfd9d4287f83a326",
            "aad1667e86904bf1b61dd69afffbbe10"
          ]
        },
        "outputId": "02f1f1a0-6356-4742-edf4-42d37b03131d"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_epochs = 100\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "total_loss = []\n",
        "\n",
        "epoch_loss = 0\n",
        "net.train()\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "    print(\"current epoch is:\",epoch)\n",
        "    epoch_loss = 0\n",
        "    for x in train_loader:\n",
        "        mse_loss = 0\n",
        "        if torch.cuda.is_available():\n",
        "          x = x.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        prediction = net(x)\n",
        "        SpatialGradient = filters.SpatialGradient()\n",
        "        loss_der = loss_func(SpatialGradient(prediction[0]), SpatialGradient(x))\n",
        "        mse_loss = loss_func(prediction[0], x) # <-- note that i'm using the input as the target\n",
        "        epoch_loss = epoch_loss + mse_loss.item() + loss_der.item()\n",
        "        (mse_loss+loss_der).backward()\n",
        "        optimizer.step()\n",
        "        #scheduler.step(epoch_loss)\n",
        "        \n",
        "    #clear_output(wait=True)\n",
        "    total_loss.append(epoch_loss)\n",
        "    print('Loss Per epoch: ',epoch_loss)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c080510f18f346e8bb1b3d87628d3efa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current epoch is: 0\n",
            "Loss Per epoch:  8.941986500823987\n",
            "current epoch is: 1\n",
            "Loss Per epoch:  8.242584959138185\n",
            "current epoch is: 2\n",
            "Loss Per epoch:  7.286656214564573\n",
            "current epoch is: 3\n",
            "Loss Per epoch:  6.558523730316665\n",
            "current epoch is: 4\n",
            "Loss Per epoch:  6.1162804795312695\n",
            "current epoch is: 5\n",
            "Loss Per epoch:  5.671708559268154\n",
            "current epoch is: 6\n",
            "Loss Per epoch:  5.310208588256501\n",
            "current epoch is: 7\n",
            "Loss Per epoch:  5.0378480845247395\n",
            "current epoch is: 8\n",
            "Loss Per epoch:  4.832292100065388\n",
            "current epoch is: 9\n",
            "Loss Per epoch:  4.6630941683542915\n",
            "current epoch is: 10\n",
            "Loss Per epoch:  4.526108065212611\n",
            "current epoch is: 11\n",
            "Loss Per epoch:  4.409322649938986\n",
            "current epoch is: 12\n",
            "Loss Per epoch:  4.3008744270773605\n",
            "current epoch is: 13\n",
            "Loss Per epoch:  4.206672451691702\n",
            "current epoch is: 14\n",
            "Loss Per epoch:  4.126817754993681\n",
            "current epoch is: 15\n",
            "Loss Per epoch:  4.0546330966753885\n",
            "current epoch is: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-180-b35dc47442e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"current epoch is:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mmse_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-173-dac40058c77d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtemp_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtemp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m#print(temp_image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print('Original Dimensions : ',temp_image.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZGQL44BbD27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(total_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unq3dKsGzLbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.cpu()\n",
        "net.eval()\n",
        "counter = 0\n",
        "for i in range(30):\n",
        "    counter = counter + 1\n",
        "    fig,ax = plt.subplots(1,2,figsize=(8,4))\n",
        "    x = Data[i]\n",
        "    input_img = x[0]\n",
        "    #print(input_img)\n",
        "    model_pred = net(x.unsqueeze(0))[0].cpu().data.numpy()[0]\n",
        "    #print(model_pred)\n",
        "    ax[0].set_title('Input SEM Image',fontsize=12)\n",
        "    ax[1].set_title('Reconstructed SEM Image',fontsize=12)\n",
        "    ax[0].imshow(input_img,cmap='gray',vmin=0,vmax=1)\n",
        "    ax[1].imshow(model_pred,cmap='gray',vmin=0,vmax=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdLRCmMwxoH",
        "colab_type": "text"
      },
      "source": [
        "Extract Latent representation from Encoder "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjiLVJshbPtN",
        "colab_type": "text"
      },
      "source": [
        "Do Clustering and calculate Silhouette Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxS4Pw-Jwpwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "Attributes = np.empty([len(train_loader),latent_dim])\n",
        "#print(Attributes.shape)\n",
        "for i,x in enumerate(Data):\n",
        "  Temp_results = net(x.unsqueeze(0))\n",
        "  #print(Temp_results[0])\n",
        "  Temp_Attributes = (Temp_results[1]).cpu().data.numpy()\n",
        "  #print(\"Temp_Attributes:\",Temp_Attributes)\n",
        "  Attributes[i] = Temp_Attributes\n",
        "  #print(Attributes[i].shape)\n",
        "#print(Attributes.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_kibUze34Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k=20\n",
        "kmeans = KMeans(n_clusters=k,random_state=0).fit(Attributes)\n",
        "Clustering_labels = kmeans.labels_\n",
        "print(Clustering_labels)\n",
        "Score = silhouette_score(Attributes,Clustering_labels)\n",
        "print(Score)\n",
        "sample_score = silhouette_samples(Attributes,Clustering_labels)\n",
        "#print(sample_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aajc2cBaaHvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max(sample_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Abl5ywHK8v",
        "colab_type": "text"
      },
      "source": [
        "Find Optimal K using Silhouette score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eGyaBQTf0EC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "column_names = [\"Image\",\"Label\",\"Score\"]\n",
        "df = pd.DataFrame(columns = column_names,index=np.arange(len(Data)))\n",
        "df['Image'][88]\n",
        "\n",
        "for i,x in enumerate(Data):\n",
        "  df['Image'][i] = (x[0]).data.numpy()\n",
        "  df['Label'][i] = Clustering_labels[i]\n",
        "  df['Score'][i] = sample_score[i]\n",
        "  #print(input_img)\n",
        "  df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ry2LOqBoDfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df= df.sort_values('Label',ignore_index=True)\n",
        "print(df)\n",
        "df['Image'][120]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScJbzHKPkOv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ncols = 7\n",
        "print(len(Data))\n",
        "nrows = int(len(Data)/ncols)\n",
        "figsize = [40, 120]  \n",
        "fig,ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
        "axi = ax.flat\n",
        "#print(len(axi))\n",
        "for i,x in enumerate(Data):\n",
        "  input_img = df['Image'][i]\n",
        "  axi[i].set_title(\"label:\"+str(df['Label'][i])+\" \"+\"Score:\"+str(round(df['Score'][i],2)),fontsize =20)\n",
        "  axi[i].imshow(input_img,cmap='gray',vmin=0,vmax=1)\n",
        "fig.tight_layout(pad=0.3)\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt652djSHKk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k_range = 20\n",
        "Score = np.empty(20)\n",
        "for k in range(k_range):\n",
        "  kmeans = KMeans(n_clusters=k+2,random_state=0).fit(Attributes)\n",
        "  Clustering_labels_k = kmeans.labels_\n",
        "  Score[k] = silhouette_score(Attributes,Clustering_labels_k)\n",
        "print(Score)\n",
        "Max_score_k = np.argmax(Score) + 2\n",
        "print(Max_score_k)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}