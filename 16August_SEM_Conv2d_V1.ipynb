{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e5d3c63091c427689afec1cfb93710c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3c16cc5d6bce4a74bcfc8493717f0d2e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_609cc8462dea4dac952d7ae0e5bcb1ec",
              "IPY_MODEL_538f53f7a4fa42e289aed016acc94fdb"
            ]
          }
        },
        "3c16cc5d6bce4a74bcfc8493717f0d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "609cc8462dea4dac952d7ae0e5bcb1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03049eb8a4b34756aafa81a5ac7fdab1",
            "_dom_classes": [],
            "description": "  4%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6dddad9574474617ad80780776a37954"
          }
        },
        "538f53f7a4fa42e289aed016acc94fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b5cce4686a1f4423a9066e94214c55d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/100 [11:55&lt;4:43:09, 176.98s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef041413847c4f29bd90609663ebbb19"
          }
        },
        "03049eb8a4b34756aafa81a5ac7fdab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6dddad9574474617ad80780776a37954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5cce4686a1f4423a9066e94214c55d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef041413847c4f29bd90609663ebbb19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NJain121442/course2020/blob/master/16August_SEM_Conv2d_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKSmgXNT75Kt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "71401ae3-2451-415a-d64f-f668738d524a"
      },
      "source": [
        "!pip install kornia\n",
        "from kornia import filters\n",
        "import torch.nn as nn\n",
        "import glob\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.display import clear_output\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from torchsummary import summary \n",
        "import matplotlib.image as mpimg\n",
        "import torchvision\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kornia in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: torch<1.7.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from kornia) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from kornia) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.7.0,>=1.6.0->kornia) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Ld9pHHC31n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9ff1a56-ab2c-4c5c-f215-0764181373d7"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Jj7TPgDTvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip '/content/drive/My Drive/AutoEncoder_training.zip' -d '/content/drive/My Drive/AutoEncoder_training' "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6krlmPnxVdHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data_path = \"/content/Fruits/\"\n",
        "#Data_path = \"/content/drive/My Drive/AutoEncoder_training/AutoEncoder_training/\"\n",
        "Data_path = \"/content/drive/My Drive/All_class_images\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u_2M6dAdOyN",
        "colab_type": "text"
      },
      "source": [
        "Lets Resize all images to same size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-mNUe39uG6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,path,new_size = 226):\n",
        "    #self.filelist = glob.glob(path+'/*.jfif')\n",
        "    self.filelist = glob.glob(path+'/*.tiff')\n",
        "    self.new_size = new_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.filelist)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    temp_filepath = self.filelist[idx]\n",
        "    temp_image = cv2.imread(temp_filepath)\n",
        "    #print(temp_image)\n",
        "    #print('Original Dimensions : ',temp_image.shape)\n",
        "    #cv2_imshow(temp_image)\n",
        "    temp_image = cv2.cvtColor(temp_image, cv2.COLOR_BGR2GRAY)\n",
        "    #print('Original Dimensions : ',temp_image.shape)\n",
        "    #cv2_imshow(temp_image)\n",
        "    #dim = (504,504)\n",
        "    #temp_image = cv2.resize(temp_image, dim, interpolation = cv2.INTER_AREA)\n",
        "    #print('Resized Dimensions : ',temp_image.shape)\n",
        "    #cv2_imshow(temp_image)\n",
        "    #print(temp_image.shape)\n",
        "    temp_image = temp_image/255\n",
        "    #plt.imshow(temp_image,cmap='gray',vmin=0,vmax=1)\n",
        "    #temp_image = torch.from_numpy(temp_image)\n",
        "    temp_image = torch.Tensor(temp_image)\n",
        "    #print(temp_image.shape)\n",
        "    #print(temp_image)\n",
        "    temp_image = temp_image.unsqueeze(0)\n",
        "    #print(temp_image.shape)\n",
        "    return temp_image"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXkStG8WkAbq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae9a0507-6712-4630-f465-c983b7206a3c"
      },
      "source": [
        "Data = CustomDataset(Data_path)\n",
        "Data[2].shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 504, 504])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tLko7rtVd0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 32\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.enc1 = nn.Conv2d(1,64,kernel_size=3,stride=3)\n",
        "        self.enc2 = nn.Conv2d(64,128,kernel_size=3,stride=3)\n",
        "        self.enc3 = nn.Conv2d(128,256,kernel_size=2,stride=3)\n",
        "        self.pool = nn.MaxPool2d(2,2,return_indices=True)\n",
        "        self.FC1 = nn.Linear(6400,2048)\n",
        "        self.FC2 = nn.Linear(2048,512)\n",
        "        self.FC3 = nn.Linear(512,latent_dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        conv1 = F.relu(self.enc1(x)) # output will be 168x168x64\n",
        "        x,indices1 = self.pool(conv1) #output will be 84x84x64\n",
        "        conv2 = F.relu(self.enc2(x)) #output will be 28x28x128\n",
        "        x,indices2 = self.pool(conv2)   # output will be 14x14x128\n",
        "        conv3 = F.relu(self.enc3(x)) #output will be 5x5x256 \n",
        "        x = conv3.view(-1,6400) # after flattening the size will be 6400\n",
        "        x = F.relu(self.FC1(x))\n",
        "        x = F.relu(self.FC2(x))\n",
        "        x = F.relu(self.FC3(x)) # the latent space representation\n",
        "        return x,indices1,indices2,conv3,conv2,conv1\n",
        "    \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.FC4 = nn.Linear(latent_dim,512)\n",
        "        self.FC5 = nn.Linear(512,2048)\n",
        "        self.FC6 = nn.Linear(2048,6400)\n",
        "        self.dec1 = nn.ConvTranspose2d(256,128, kernel_size=2, stride=3)  \n",
        "        self.dec2 = nn.ConvTranspose2d(128,64, kernel_size=3, stride=3)\n",
        "        self.dec3 = nn.ConvTranspose2d(64 ,1, kernel_size=3, stride=3)\n",
        "        self.unpool = nn.MaxUnpool2d(2,2,padding=0)\n",
        "        \n",
        "        \n",
        "    def forward(self,x,indices1,indices2,conv3,conv2,conv1):\n",
        "        x = F.relu(self.FC4(x))\n",
        "        x = F.relu(self.FC5(x))  #size back to 2048\n",
        "        x = F.relu(self.FC6(x)) #size back to 6400\n",
        "        x = torch.reshape(x,(1,256,5,5))\n",
        "        x = F.relu(self.dec1(x)) # ouput will be 14x14x128\n",
        "        x = self.unpool(x,indices2) #output will be 28x28x128\n",
        "        x = F.relu(self.dec2(x)) # output will be 84x84x64\n",
        "        x = self.unpool(x,indices1) #output will be 168x168x64\n",
        "        #x = self.dec3(x) # output will be 504x504x1\n",
        "        x = torch.sigmoid(self.dec3(x)) # output will be 504x504x1\n",
        "        return x\n",
        "    \n",
        "class Conv2d_AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Conv2d_AutoEncoder, self).__init__()\n",
        "\n",
        "        self.enc = Encoder()\n",
        "        self.dec = Decoder()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        z,indices1,indices2,conv3,conv2,conv1 = self.enc(x)\n",
        "        \n",
        "        out = self.dec(z,indices1,indices2,conv3,conv2,conv1)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaMlwOS5oEI2",
        "colab_type": "text"
      },
      "source": [
        "**Lets write the first Auto encoder **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q38XOqy27ViA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c3f4d756-ee77-4f1e-a38f-2d40430719a3"
      },
      "source": [
        "net = Conv2d_AutoEncoder()\n",
        "print(net)\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "#summary(net,input_size=(1,504,504))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv2d_AutoEncoder(\n",
            "  (enc): Encoder(\n",
            "    (enc1): Conv2d(1, 64, kernel_size=(3, 3), stride=(3, 3))\n",
            "    (enc2): Conv2d(64, 128, kernel_size=(3, 3), stride=(3, 3))\n",
            "    (enc3): Conv2d(128, 256, kernel_size=(2, 2), stride=(3, 3))\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (FC1): Linear(in_features=6400, out_features=2048, bias=True)\n",
            "    (FC2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "    (FC3): Linear(in_features=512, out_features=32, bias=True)\n",
            "  )\n",
            "  (dec): Decoder(\n",
            "    (FC4): Linear(in_features=32, out_features=512, bias=True)\n",
            "    (FC5): Linear(in_features=512, out_features=2048, bias=True)\n",
            "    (FC6): Linear(in_features=2048, out_features=6400, bias=True)\n",
            "    (dec1): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(3, 3))\n",
            "    (dec2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(3, 3))\n",
            "    (dec3): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(3, 3))\n",
            "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iGHRxfswour",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(Data,batch_size=1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exgsyM0UKOB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.MSELoss()\n",
        "#loss_func = nn.L1Loss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001) \n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUWlp2R-bYP9",
        "colab_type": "text"
      },
      "source": [
        "Training the Auto encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcg-ESdIwSvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559,
          "referenced_widgets": [
            "2e5d3c63091c427689afec1cfb93710c",
            "3c16cc5d6bce4a74bcfc8493717f0d2e",
            "609cc8462dea4dac952d7ae0e5bcb1ec",
            "538f53f7a4fa42e289aed016acc94fdb",
            "03049eb8a4b34756aafa81a5ac7fdab1",
            "6dddad9574474617ad80780776a37954",
            "b5cce4686a1f4423a9066e94214c55d9",
            "ef041413847c4f29bd90609663ebbb19"
          ]
        },
        "outputId": "484c3ba5-81c4-4e87-d967-5e37ffe47e3c"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_epochs = 100\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "total_loss = []\n",
        "\n",
        "epoch_loss = 0\n",
        "net.train()\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "    print(\"current epoch is:\",epoch)\n",
        "    epoch_loss = 0\n",
        "    for x in train_loader:\n",
        "        mse_loss = 0\n",
        "        if torch.cuda.is_available():\n",
        "          x = x.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        prediction = net(x)\n",
        "        SpatialGradient = filters.SpatialGradient()\n",
        "        loss_der = loss_func(SpatialGradient(prediction), SpatialGradient(x))\n",
        "        mse_loss = loss_func(prediction, x) # <-- note that i'm using the input as the target\n",
        "        epoch_loss = epoch_loss + mse_loss.item() + loss_der.item()\n",
        "        (mse_loss+loss_der).backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    #clear_output(wait=True)\n",
        "    total_loss.append(epoch_loss)\n",
        "    print('Loss Per epoch: ',epoch_loss)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e5d3c63091c427689afec1cfb93710c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current epoch is: 0\n",
            "Loss Per epoch:  13.582404528424377\n",
            "current epoch is: 1\n",
            "Loss Per epoch:  12.204537979967427\n",
            "current epoch is: 2\n",
            "Loss Per epoch:  11.396558184293099\n",
            "current epoch is: 3\n",
            "Loss Per epoch:  10.70087097666692\n",
            "current epoch is: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-44c242856b2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"current epoch is:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mmse_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-dac40058c77d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtemp_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtemp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m#print(temp_image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print('Original Dimensions : ',temp_image.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZGQL44BbD27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(total_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unq3dKsGzLbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.cpu()\n",
        "net.eval()\n",
        "counter = 0\n",
        "for i in range(30):\n",
        "    counter = counter + 1\n",
        "    fig,ax = plt.subplots(1,2,figsize=(8,4))\n",
        "    x = Data[i]\n",
        "    input_img = x[0]\n",
        "    #print(input_img)\n",
        "    model_pred = net(x.unsqueeze(0))[0].cpu().data.numpy()[0]\n",
        "    #print(model_pred)\n",
        "    ax[0].set_title('Input SEM Image',fontsize=12)\n",
        "    ax[1].set_title('Reconstructed SEM Image',fontsize=12)\n",
        "    ax[0].imshow(input_img,cmap='gray',vmin=0,vmax=1)\n",
        "    ax[1].imshow(model_pred,cmap='gray',vmin=0,vmax=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdLRCmMwxoH",
        "colab_type": "text"
      },
      "source": [
        "Extract Latent representation from Encoder "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjiLVJshbPtN",
        "colab_type": "text"
      },
      "source": [
        "Do Clustering and calculate Silhouette Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxS4Pw-Jwpwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "Encoder_net = Encoder()\n",
        "Attributes = np.empty([len(train_loader),latent_dim])\n",
        "#print(Attributes.shape)\n",
        "for i,x in enumerate(Data):\n",
        "  Temp_results = Encoder_net(x.unsqueeze(0))\n",
        "  #print(Temp_results[0])\n",
        "  Temp_Attributes = (Temp_results[0]).cpu().data.numpy()\n",
        "  #print(\"Temp_Attributes:\",Temp_Attributes)\n",
        "  Attributes[i] = Temp_Attributes\n",
        "  #print(Attributes[i].shape)\n",
        "#print(Attributes.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_kibUze34Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k=15\n",
        "kmeans = KMeans(n_clusters=k,random_state=0).fit(Attributes)\n",
        "Clustering_labels = kmeans.labels_\n",
        "print(Clustering_labels)\n",
        "Score = silhouette_score(Attributes,Clustering_labels)\n",
        "print(Score)\n",
        "sample_score = silhouette_samples(Attributes,Clustering_labels)\n",
        "#print(sample_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aajc2cBaaHvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max(sample_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Abl5ywHK8v",
        "colab_type": "text"
      },
      "source": [
        "Find Optimal K using Silhouette score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eGyaBQTf0EC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "column_names = [\"Image\",\"Label\",\"Score\"]\n",
        "df = pd.DataFrame(columns = column_names,index=np.arange(len(Data)))\n",
        "df['Image'][88]\n",
        "\n",
        "for i,x in enumerate(Data):\n",
        "  df['Image'][i] = (x[0]).data.numpy()\n",
        "  df['Label'][i] = Clustering_labels[i]\n",
        "  df['Score'][i] = sample_score[i]\n",
        "  #print(input_img)\n",
        "  df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ry2LOqBoDfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df= df.sort_values('Label',ignore_index=True)\n",
        "print(df)\n",
        "df['Image'][120]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScJbzHKPkOv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ncols = 7\n",
        "print(len(Data))\n",
        "nrows = int(len(Data)/ncols)\n",
        "figsize = [40, 120]  \n",
        "fig,ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
        "axi = ax.flat\n",
        "#print(len(axi))\n",
        "for i,x in enumerate(Data):\n",
        "  input_img = df['Image'][i]\n",
        "  axi[i].set_title(\"label:\"+str(df['Label'][i])+\" \"+\"Score:\"+str(round(df['Score'][i],2)),fontsize =20)\n",
        "  axi[i].imshow(input_img,cmap='gray',vmin=0,vmax=1)\n",
        "fig.tight_layout(pad=0.3)\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt652djSHKk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k_range = 20\n",
        "Score = np.empty(20)\n",
        "for k in range(k_range):\n",
        "  kmeans = KMeans(n_clusters=k+2,random_state=0).fit(Attributes)\n",
        "  Clustering_labels_k = kmeans.labels_\n",
        "  Score[k] = silhouette_score(Attributes,Clustering_labels_k)\n",
        "print(Score)\n",
        "Max_score_k = np.argmax(Score) + 2\n",
        "print(Max_score_k)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}