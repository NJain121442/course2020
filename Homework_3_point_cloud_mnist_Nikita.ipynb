{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Homework_3_point_cloud_mnist.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "faff153761aa45b98c57edcbb064d952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_87c8999381e547d7b5c9a22cde2296a4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e02a36c05e1b4b61a0e189a0faa3f85b",
              "IPY_MODEL_a945f37ce4e747f08cc1760900e9b84b"
            ]
          }
        },
        "87c8999381e547d7b5c9a22cde2296a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e02a36c05e1b4b61a0e189a0faa3f85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c87614bab5d400fab17afa8c8426f7a",
            "_dom_classes": [],
            "description": "  4%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61040063c7714eafa010126ee86ab2dd"
          }
        },
        "a945f37ce4e747f08cc1760900e9b84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be797968e2ee4d0093e837eb4737273b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/25 [00:25&lt;05:29, 13.73s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c05c1c3fd3a44d24ae2b3579f18d36e8"
          }
        },
        "2c87614bab5d400fab17afa8c8426f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61040063c7714eafa010126ee86ab2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be797968e2ee4d0093e837eb4737273b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c05c1c3fd3a44d24ae2b3579f18d36e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NJain121442/course2020/blob/master/Homework_3_point_cloud_mnist_Nikita.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9eac0TWJB_U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "29ac4b7d-6f9c-4896-8467-51a2e7299d30"
      },
      "source": [
        "pip install tables --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tables\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables) (1.18.5)\n",
            "Installing collected packages: tables\n",
            "  Found existing installation: tables 3.4.4\n",
            "    Uninstalling tables-3.4.4:\n",
            "      Successfully uninstalled tables-3.4.4\n",
            "Successfully installed tables-3.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjlx5CdzFEsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83To5-lzFlrc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "e0d892a2-18a5-45b3-e8d4-68aab902f6f1"
      },
      "source": [
        "!wget -O  Data.zip https://www.dropbox.com/sh/h7wj4owo5vxwzgp/AACdZ5vjsHRv6utQk0_ZtIH4a?dl=0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-23 14:40:45--  https://www.dropbox.com/sh/h7wj4owo5vxwzgp/AACdZ5vjsHRv6utQk0_ZtIH4a?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1, 2620:100:6018:1::a27d:301\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/raw/h7wj4owo5vxwzgp/AACdZ5vjsHRv6utQk0_ZtIH4a [following]\n",
            "--2020-06-23 14:40:45--  https://www.dropbox.com/sh/raw/h7wj4owo5vxwzgp/AACdZ5vjsHRv6utQk0_ZtIH4a\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucedbdb72ebd0f1c8c26bdb97b54.dl.dropboxusercontent.com/zip_download_get/AdnmTmikeo4VP9FamK9CzLBz-RLaf03Vs1qcNrzjdYgCEf_z6fT90Go31hRPh2XM80kHhLxnKAic_8FKlfx9jPxBQk6S3CpGci971dcaZ79mjQ [following]\n",
            "--2020-06-23 14:40:46--  https://ucedbdb72ebd0f1c8c26bdb97b54.dl.dropboxusercontent.com/zip_download_get/AdnmTmikeo4VP9FamK9CzLBz-RLaf03Vs1qcNrzjdYgCEf_z6fT90Go31hRPh2XM80kHhLxnKAic_8FKlfx9jPxBQk6S3CpGci971dcaZ79mjQ\n",
            "Resolving ucedbdb72ebd0f1c8c26bdb97b54.dl.dropboxusercontent.com (ucedbdb72ebd0f1c8c26bdb97b54.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to ucedbdb72ebd0f1c8c26bdb97b54.dl.dropboxusercontent.com (ucedbdb72ebd0f1c8c26bdb97b54.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75147062 (72M) [application/zip]\n",
            "Saving to: ‘Data.zip’\n",
            "\n",
            "Data.zip            100%[===================>]  71.67M  16.6MB/s    in 4.3s    \n",
            "\n",
            "2020-06-23 14:40:51 (16.6 MB/s) - ‘Data.zip’ saved [75147062/75147062]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxnOx_tggxLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9027caf5-2b80-4802-fa93-e2969b34d5f5"
      },
      "source": [
        "!unzip /content/Data.zip -d /content/Data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/Data.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            " extracting: /content/Data/valid_ds.h5  \n",
            " extracting: /content/Data/training_ds.h5  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEPp-0I1HZYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = pd.read_hdf('/content/Data/training_ds.h5')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy0iff_XFEsx",
        "colab_type": "text"
      },
      "source": [
        "# Homework 3\n",
        "## Point Cloud MNIST with DeepSet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqYpFOe2FEsy",
        "colab_type": "text"
      },
      "source": [
        "below you have a custom dataloader for the point-cloud MNIST dataset,\n",
        "\n",
        "the training and validation datasets are linked from the course website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGcolM_3FEsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        \n",
        "\n",
        "        \n",
        "        self.df = pd.read_hdf(path)\n",
        "        \n",
        "        self.label = torch.LongTensor(self.df.label)\n",
        "        \n",
        "        self.n_points = self.df.n_points\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "       \n",
        "        return len(self.label)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "    \n",
        "        return torch.FloatTensor(self.df.iloc[idx].xy), self.label[idx]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yonjFSthFEs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = CustomDataset('/content/Data/training_ds.h5')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inBZp9PLFEs9",
        "colab_type": "text"
      },
      "source": [
        "#### the data is exactly like the MNIST dataset, except that instead of a 28x28 image,\n",
        "#### you get a (N x 2) array of points (different number of points for each item in the dataset) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmsnIHA8FEs9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "05a5c6e3-b346-4490-9c45-6b0f36c9cadd"
      },
      "source": [
        "fig,ax = plt.subplots(figsize=(5,5))\n",
        "\n",
        "xy = ds[445][0]\n",
        "\n",
        "ax.scatter( xy[:,0],xy[:,1] )\n",
        "\n",
        "ax.set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkAv1HxkFEtB",
        "colab_type": "text"
      },
      "source": [
        "### the dataset object has a n_points variable that tells us how many points in each item"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_chwDlsAFEtC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "eba44950-8d2e-496f-b9ac-489ed53951ce"
      },
      "source": [
        "ds.n_points"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       117\n",
              "1       130\n",
              "2        88\n",
              "3        70\n",
              "4        97\n",
              "       ... \n",
              "9995    120\n",
              "9996    111\n",
              "9997    114\n",
              "9998     81\n",
              "9999     88\n",
              "Name: n_points, Length: 10000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiFbrnWEFEtF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5cf0acbc-9041-4969-93aa-8a78480c5228"
      },
      "source": [
        "plt.hist(ds.n_points,np.linspace(19.5,260.5,242))\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5lmzvzwFEtM",
        "colab_type": "text"
      },
      "source": [
        "## One way to deal with this variable size is to use a custom Batch Sampler\n",
        "\n",
        "https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "This object will tell our dataloader which item indices to request for the batches - \n",
        "and we can \"rig\" it to return batches where all the items have the same N, and therefore we can stack them without a custom colate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JalLewdIFEtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomBatchSampler(Sampler):\n",
        "    def __init__(self, points_per_entry, batch_size):\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        self.N_per_entry = points_per_entry\n",
        "        self.batches = {}\n",
        "        \n",
        "    def generate_batches(self):\n",
        "        \n",
        "        self.entries_with_N = {}\n",
        "        running_idx = -1\n",
        "\n",
        "        for N in set(self.N_per_entry):\n",
        "            \n",
        "            self.entries_with_N[N] = np.where(self.N_per_entry == N)[0]\n",
        "\n",
        "            how_many = len(self.entries_with_N[N])\n",
        "            n_batches = np.amax([ how_many / self.batch_size, 1])\n",
        "\n",
        "            self.entries_with_N[N] = np.array_split(np.random.permutation(self.entries_with_N[N]),\n",
        "                                                           n_batches)\n",
        "            for batch in self.entries_with_N[N]:\n",
        "                running_idx += 1\n",
        "                self.batches[running_idx] = batch\n",
        "\n",
        "        self.n_batches = running_idx + 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_batches\n",
        "\n",
        "    def __iter__(self):\n",
        "        \n",
        "        self.generate_batches()\n",
        "        \n",
        "        batch_order = np.random.permutation(np.arange(self.n_batches))\n",
        "        for i in batch_order:\n",
        "            yield self.batches[i]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRAai43WFEtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 120\n",
        "batch_sampler = CustomBatchSampler(ds.n_points, batch_size)\n",
        "train_data_loader = DataLoader(ds, batch_sampler=batch_sampler)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmthJHPOFEtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "838da795-cd15-4fe2-f03d-2f5163ee91ae"
      },
      "source": [
        "for epoch in range(3):\n",
        "    for x,y in train_data_loader:\n",
        "        print(x.shape)\n",
        "        print(x.size(0))\n",
        "        print(y.shape)\n",
        "    break"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 249, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([1, 225, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([49, 157, 2])\n",
            "49\n",
            "torch.Size([49])\n",
            "torch.Size([62, 146, 2])\n",
            "62\n",
            "torch.Size([62])\n",
            "torch.Size([1, 228, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([59, 141, 2])\n",
            "59\n",
            "torch.Size([59])\n",
            "torch.Size([4, 212, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([21, 179, 2])\n",
            "21\n",
            "torch.Size([21])\n",
            "torch.Size([53, 151, 2])\n",
            "53\n",
            "torch.Size([53])\n",
            "torch.Size([75, 69, 2])\n",
            "75\n",
            "torch.Size([75])\n",
            "torch.Size([4, 208, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([8, 194, 2])\n",
            "8\n",
            "torch.Size([8])\n",
            "torch.Size([31, 52, 2])\n",
            "31\n",
            "torch.Size([31])\n",
            "torch.Size([35, 163, 2])\n",
            "35\n",
            "torch.Size([35])\n",
            "torch.Size([73, 73, 2])\n",
            "73\n",
            "torch.Size([73])\n",
            "torch.Size([127, 109, 2])\n",
            "127\n",
            "torch.Size([127])\n",
            "torch.Size([21, 47, 2])\n",
            "21\n",
            "torch.Size([21])\n",
            "torch.Size([19, 42, 2])\n",
            "19\n",
            "torch.Size([19])\n",
            "torch.Size([10, 192, 2])\n",
            "10\n",
            "torch.Size([10])\n",
            "torch.Size([118, 102, 2])\n",
            "118\n",
            "torch.Size([118])\n",
            "torch.Size([8, 199, 2])\n",
            "8\n",
            "torch.Size([8])\n",
            "torch.Size([98, 92, 2])\n",
            "98\n",
            "torch.Size([98])\n",
            "torch.Size([3, 219, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([89, 114, 2])\n",
            "89\n",
            "torch.Size([89])\n",
            "torch.Size([37, 171, 2])\n",
            "37\n",
            "torch.Size([37])\n",
            "torch.Size([78, 132, 2])\n",
            "78\n",
            "torch.Size([78])\n",
            "torch.Size([15, 187, 2])\n",
            "15\n",
            "torch.Size([15])\n",
            "torch.Size([60, 138, 2])\n",
            "60\n",
            "torch.Size([60])\n",
            "torch.Size([23, 45, 2])\n",
            "23\n",
            "torch.Size([23])\n",
            "torch.Size([4, 206, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([12, 189, 2])\n",
            "12\n",
            "torch.Size([12])\n",
            "torch.Size([106, 111, 2])\n",
            "106\n",
            "torch.Size([106])\n",
            "torch.Size([93, 85, 2])\n",
            "93\n",
            "torch.Size([93])\n",
            "torch.Size([28, 177, 2])\n",
            "28\n",
            "torch.Size([28])\n",
            "torch.Size([125, 107, 2])\n",
            "125\n",
            "torch.Size([125])\n",
            "torch.Size([3, 227, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([95, 130, 2])\n",
            "95\n",
            "torch.Size([95])\n",
            "torch.Size([1, 242, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([7, 220, 2])\n",
            "7\n",
            "torch.Size([7])\n",
            "torch.Size([102, 77, 2])\n",
            "102\n",
            "torch.Size([102])\n",
            "torch.Size([115, 110, 2])\n",
            "115\n",
            "torch.Size([115])\n",
            "torch.Size([98, 97, 2])\n",
            "98\n",
            "torch.Size([98])\n",
            "torch.Size([55, 154, 2])\n",
            "55\n",
            "torch.Size([55])\n",
            "torch.Size([33, 170, 2])\n",
            "33\n",
            "torch.Size([33])\n",
            "torch.Size([12, 200, 2])\n",
            "12\n",
            "torch.Size([12])\n",
            "torch.Size([11, 183, 2])\n",
            "11\n",
            "torch.Size([11])\n",
            "torch.Size([1, 280, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([94, 84, 2])\n",
            "94\n",
            "torch.Size([94])\n",
            "torch.Size([16, 190, 2])\n",
            "16\n",
            "torch.Size([16])\n",
            "torch.Size([46, 63, 2])\n",
            "46\n",
            "torch.Size([46])\n",
            "torch.Size([92, 120, 2])\n",
            "92\n",
            "torch.Size([92])\n",
            "torch.Size([35, 57, 2])\n",
            "35\n",
            "torch.Size([35])\n",
            "torch.Size([16, 40, 2])\n",
            "16\n",
            "torch.Size([16])\n",
            "torch.Size([27, 173, 2])\n",
            "27\n",
            "torch.Size([27])\n",
            "torch.Size([23, 176, 2])\n",
            "23\n",
            "torch.Size([23])\n",
            "torch.Size([16, 44, 2])\n",
            "16\n",
            "torch.Size([16])\n",
            "torch.Size([1, 247, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([1, 26, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([112, 113, 2])\n",
            "112\n",
            "torch.Size([112])\n",
            "torch.Size([3, 210, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([25, 46, 2])\n",
            "25\n",
            "torch.Size([25])\n",
            "torch.Size([24, 180, 2])\n",
            "24\n",
            "torch.Size([24])\n",
            "torch.Size([53, 139, 2])\n",
            "53\n",
            "torch.Size([53])\n",
            "torch.Size([30, 167, 2])\n",
            "30\n",
            "torch.Size([30])\n",
            "torch.Size([110, 90, 2])\n",
            "110\n",
            "torch.Size([110])\n",
            "torch.Size([77, 98, 2])\n",
            "77\n",
            "torch.Size([77])\n",
            "torch.Size([39, 166, 2])\n",
            "39\n",
            "torch.Size([39])\n",
            "torch.Size([104, 119, 2])\n",
            "104\n",
            "torch.Size([104])\n",
            "torch.Size([58, 152, 2])\n",
            "58\n",
            "torch.Size([58])\n",
            "torch.Size([36, 161, 2])\n",
            "36\n",
            "torch.Size([36])\n",
            "torch.Size([96, 103, 2])\n",
            "96\n",
            "torch.Size([96])\n",
            "torch.Size([33, 162, 2])\n",
            "33\n",
            "torch.Size([33])\n",
            "torch.Size([49, 149, 2])\n",
            "49\n",
            "torch.Size([49])\n",
            "torch.Size([82, 83, 2])\n",
            "82\n",
            "torch.Size([82])\n",
            "torch.Size([63, 147, 2])\n",
            "63\n",
            "torch.Size([63])\n",
            "torch.Size([1, 234, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([78, 140, 2])\n",
            "78\n",
            "torch.Size([78])\n",
            "torch.Size([1, 25, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([2, 31, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([5, 203, 2])\n",
            "5\n",
            "torch.Size([5])\n",
            "torch.Size([118, 106, 2])\n",
            "118\n",
            "torch.Size([118])\n",
            "torch.Size([66, 70, 2])\n",
            "66\n",
            "torch.Size([66])\n",
            "torch.Size([36, 158, 2])\n",
            "36\n",
            "torch.Size([36])\n",
            "torch.Size([4, 202, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([55, 153, 2])\n",
            "55\n",
            "torch.Size([55])\n",
            "torch.Size([106, 99, 2])\n",
            "106\n",
            "torch.Size([106])\n",
            "torch.Size([64, 145, 2])\n",
            "64\n",
            "torch.Size([64])\n",
            "torch.Size([23, 48, 2])\n",
            "23\n",
            "torch.Size([23])\n",
            "torch.Size([8, 195, 2])\n",
            "8\n",
            "torch.Size([8])\n",
            "torch.Size([108, 124, 2])\n",
            "108\n",
            "torch.Size([108])\n",
            "torch.Size([50, 156, 2])\n",
            "50\n",
            "torch.Size([50])\n",
            "torch.Size([29, 54, 2])\n",
            "29\n",
            "torch.Size([29])\n",
            "torch.Size([96, 81, 2])\n",
            "96\n",
            "torch.Size([96])\n",
            "torch.Size([103, 93, 2])\n",
            "103\n",
            "torch.Size([103])\n",
            "torch.Size([68, 62, 2])\n",
            "68\n",
            "torch.Size([68])\n",
            "torch.Size([2, 245, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([92, 126, 2])\n",
            "92\n",
            "torch.Size([92])\n",
            "torch.Size([2, 27, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([40, 59, 2])\n",
            "40\n",
            "torch.Size([40])\n",
            "torch.Size([11, 197, 2])\n",
            "11\n",
            "torch.Size([11])\n",
            "torch.Size([80, 72, 2])\n",
            "80\n",
            "torch.Size([80])\n",
            "torch.Size([114, 108, 2])\n",
            "114\n",
            "torch.Size([114])\n",
            "torch.Size([126, 104, 2])\n",
            "126\n",
            "torch.Size([126])\n",
            "torch.Size([67, 137, 2])\n",
            "67\n",
            "torch.Size([67])\n",
            "torch.Size([5, 214, 2])\n",
            "5\n",
            "torch.Size([5])\n",
            "torch.Size([81, 75, 2])\n",
            "81\n",
            "torch.Size([81])\n",
            "torch.Size([5, 36, 2])\n",
            "5\n",
            "torch.Size([5])\n",
            "torch.Size([25, 172, 2])\n",
            "25\n",
            "torch.Size([25])\n",
            "torch.Size([100, 117, 2])\n",
            "100\n",
            "torch.Size([100])\n",
            "torch.Size([4, 218, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([84, 74, 2])\n",
            "84\n",
            "torch.Size([84])\n",
            "torch.Size([45, 56, 2])\n",
            "45\n",
            "torch.Size([45])\n",
            "torch.Size([14, 182, 2])\n",
            "14\n",
            "torch.Size([14])\n",
            "torch.Size([1, 241, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([8, 196, 2])\n",
            "8\n",
            "torch.Size([8])\n",
            "torch.Size([2, 216, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([81, 122, 2])\n",
            "81\n",
            "torch.Size([81])\n",
            "torch.Size([115, 101, 2])\n",
            "115\n",
            "torch.Size([115])\n",
            "torch.Size([6, 205, 2])\n",
            "6\n",
            "torch.Size([6])\n",
            "torch.Size([105, 105, 2])\n",
            "105\n",
            "torch.Size([105])\n",
            "torch.Size([7, 34, 2])\n",
            "7\n",
            "torch.Size([7])\n",
            "torch.Size([97, 79, 2])\n",
            "97\n",
            "torch.Size([97])\n",
            "torch.Size([7, 201, 2])\n",
            "7\n",
            "torch.Size([7])\n",
            "torch.Size([81, 82, 2])\n",
            "81\n",
            "torch.Size([81])\n",
            "torch.Size([20, 174, 2])\n",
            "20\n",
            "torch.Size([20])\n",
            "torch.Size([41, 159, 2])\n",
            "41\n",
            "torch.Size([41])\n",
            "torch.Size([120, 86, 2])\n",
            "120\n",
            "torch.Size([120])\n",
            "torch.Size([75, 66, 2])\n",
            "75\n",
            "torch.Size([75])\n",
            "torch.Size([4, 213, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([18, 191, 2])\n",
            "18\n",
            "torch.Size([18])\n",
            "torch.Size([6, 193, 2])\n",
            "6\n",
            "torch.Size([6])\n",
            "torch.Size([53, 60, 2])\n",
            "53\n",
            "torch.Size([53])\n",
            "torch.Size([108, 96, 2])\n",
            "108\n",
            "torch.Size([108])\n",
            "torch.Size([13, 39, 2])\n",
            "13\n",
            "torch.Size([13])\n",
            "torch.Size([96, 89, 2])\n",
            "96\n",
            "torch.Size([96])\n",
            "torch.Size([78, 71, 2])\n",
            "78\n",
            "torch.Size([78])\n",
            "torch.Size([47, 135, 2])\n",
            "47\n",
            "torch.Size([47])\n",
            "torch.Size([35, 164, 2])\n",
            "35\n",
            "torch.Size([35])\n",
            "torch.Size([30, 168, 2])\n",
            "30\n",
            "torch.Size([30])\n",
            "torch.Size([4, 215, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([1, 229, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([1, 243, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([30, 175, 2])\n",
            "30\n",
            "torch.Size([30])\n",
            "torch.Size([71, 148, 2])\n",
            "71\n",
            "torch.Size([71])\n",
            "torch.Size([84, 131, 2])\n",
            "84\n",
            "torch.Size([84])\n",
            "torch.Size([4, 37, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([102, 121, 2])\n",
            "102\n",
            "torch.Size([102])\n",
            "torch.Size([73, 67, 2])\n",
            "73\n",
            "torch.Size([73])\n",
            "torch.Size([76, 133, 2])\n",
            "76\n",
            "torch.Size([76])\n",
            "torch.Size([105, 118, 2])\n",
            "105\n",
            "torch.Size([105])\n",
            "torch.Size([3, 35, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([12, 43, 2])\n",
            "12\n",
            "torch.Size([12])\n",
            "torch.Size([110, 88, 2])\n",
            "110\n",
            "torch.Size([110])\n",
            "torch.Size([28, 50, 2])\n",
            "28\n",
            "torch.Size([28])\n",
            "torch.Size([108, 91, 2])\n",
            "108\n",
            "torch.Size([108])\n",
            "torch.Size([63, 68, 2])\n",
            "63\n",
            "torch.Size([63])\n",
            "torch.Size([45, 65, 2])\n",
            "45\n",
            "torch.Size([45])\n",
            "torch.Size([102, 87, 2])\n",
            "102\n",
            "torch.Size([102])\n",
            "torch.Size([4, 217, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([98, 115, 2])\n",
            "98\n",
            "torch.Size([98])\n",
            "torch.Size([1, 30, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([2, 239, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([114, 116, 2])\n",
            "114\n",
            "torch.Size([114])\n",
            "torch.Size([8, 38, 2])\n",
            "8\n",
            "torch.Size([8])\n",
            "torch.Size([82, 129, 2])\n",
            "82\n",
            "torch.Size([82])\n",
            "torch.Size([86, 128, 2])\n",
            "86\n",
            "torch.Size([86])\n",
            "torch.Size([66, 142, 2])\n",
            "66\n",
            "torch.Size([66])\n",
            "torch.Size([18, 188, 2])\n",
            "18\n",
            "torch.Size([18])\n",
            "torch.Size([48, 155, 2])\n",
            "48\n",
            "torch.Size([48])\n",
            "torch.Size([27, 165, 2])\n",
            "27\n",
            "torch.Size([27])\n",
            "torch.Size([9, 198, 2])\n",
            "9\n",
            "torch.Size([9])\n",
            "torch.Size([54, 64, 2])\n",
            "54\n",
            "torch.Size([54])\n",
            "torch.Size([14, 184, 2])\n",
            "14\n",
            "torch.Size([14])\n",
            "torch.Size([84, 76, 2])\n",
            "84\n",
            "torch.Size([84])\n",
            "torch.Size([1, 29, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([1, 236, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([104, 123, 2])\n",
            "104\n",
            "torch.Size([104])\n",
            "torch.Size([36, 160, 2])\n",
            "36\n",
            "torch.Size([36])\n",
            "torch.Size([72, 143, 2])\n",
            "72\n",
            "torch.Size([72])\n",
            "torch.Size([4, 204, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([5, 209, 2])\n",
            "5\n",
            "torch.Size([5])\n",
            "torch.Size([1, 226, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([81, 125, 2])\n",
            "81\n",
            "torch.Size([81])\n",
            "torch.Size([107, 94, 2])\n",
            "107\n",
            "torch.Size([107])\n",
            "torch.Size([12, 181, 2])\n",
            "12\n",
            "torch.Size([12])\n",
            "torch.Size([2, 223, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([33, 55, 2])\n",
            "33\n",
            "torch.Size([33])\n",
            "torch.Size([3, 28, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([26, 51, 2])\n",
            "26\n",
            "torch.Size([26])\n",
            "torch.Size([116, 95, 2])\n",
            "116\n",
            "torch.Size([116])\n",
            "torch.Size([3, 33, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([3, 233, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([29, 49, 2])\n",
            "29\n",
            "torch.Size([29])\n",
            "torch.Size([8, 41, 2])\n",
            "8\n",
            "torch.Size([8])\n",
            "torch.Size([30, 53, 2])\n",
            "30\n",
            "torch.Size([30])\n",
            "torch.Size([23, 178, 2])\n",
            "23\n",
            "torch.Size([23])\n",
            "torch.Size([90, 80, 2])\n",
            "90\n",
            "torch.Size([90])\n",
            "torch.Size([116, 100, 2])\n",
            "116\n",
            "torch.Size([116])\n",
            "torch.Size([35, 169, 2])\n",
            "35\n",
            "torch.Size([35])\n",
            "torch.Size([39, 58, 2])\n",
            "39\n",
            "torch.Size([39])\n",
            "torch.Size([104, 78, 2])\n",
            "104\n",
            "torch.Size([104])\n",
            "torch.Size([53, 150, 2])\n",
            "53\n",
            "torch.Size([53])\n",
            "torch.Size([92, 134, 2])\n",
            "92\n",
            "torch.Size([92])\n",
            "torch.Size([3, 221, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([19, 185, 2])\n",
            "19\n",
            "torch.Size([19])\n",
            "torch.Size([42, 61, 2])\n",
            "42\n",
            "torch.Size([42])\n",
            "torch.Size([1, 230, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([90, 127, 2])\n",
            "90\n",
            "torch.Size([90])\n",
            "torch.Size([2, 211, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([55, 144, 2])\n",
            "55\n",
            "torch.Size([55])\n",
            "torch.Size([2, 207, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([111, 112, 2])\n",
            "111\n",
            "torch.Size([111])\n",
            "torch.Size([17, 186, 2])\n",
            "17\n",
            "torch.Size([17])\n",
            "torch.Size([75, 136, 2])\n",
            "75\n",
            "torch.Size([75])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH9V8XKXFEtV",
        "colab_type": "text"
      },
      "source": [
        "## Building a DeepSet model\n",
        "\n",
        "you only have three components - a fully connected network that creates the node embedding, a sum operation, and a classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYPp1NTyFEtV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12490bb6-5faa-46ce-cbc2-0ec143a80dd8"
      },
      "source": [
        "# the linear layer operates on the last dimension:\n",
        "\n",
        "linear_layer = nn.Linear(10,5)\n",
        "\n",
        "linear_layer(  torch.rand((345,10)) ).shape, linear_layer(  torch.rand((345,76,10)) ).shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([345, 5]), torch.Size([345, 76, 5]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NrQjHLVFEtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5c8398b2-7d45-4d30-8d8c-eb46210c2c62"
      },
      "source": [
        "# for the the mean operation you need to specify the dimension:\n",
        "\n",
        "x = torch.rand((42,15,10))\n",
        "\n",
        "torch.mean(x,dim=1).shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([42, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV1Q7Y5FFEtf",
        "colab_type": "text"
      },
      "source": [
        "## build the model, train, submit when you reach above 75% accuracy on the validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecZ_l1gcFEtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepSet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepSet, self).__init__()\n",
        "        self.embedding1 = nn.Linear(2,16)\n",
        "        #self.embedding2 = nn.Linear(16,64)\n",
        "        self.embedding3 = nn.Linear(64,512)\n",
        "        self.linear1 = nn.Linear(512,32)\n",
        "        self.linear2 = nn.Linear(32,10)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.embedding1(x))\n",
        "        x = F.relu(self.embedding2(x))\n",
        "        x = F.relu(self.embedding3(x))\n",
        "        x = torch.mean(x,1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYn1B_DoFEti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = DeepSet()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oXUu5RbFEtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.cuda\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iuXfbolFEtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4uTIu00FEtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyZRYcivFEt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(data_loader,net):\n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    total_number = 0\n",
        "    total_correct = 0\n",
        "    \n",
        "    for x,y in data_loader:\n",
        "        if torch.cuda.is_available():\n",
        "          x,y = x.cuda(),y.cuda()\n",
        "        \n",
        "        prediction = net(x).cpu().data.numpy()\n",
        "        prediction = np.argmax(prediction,axis=1)\n",
        "        y = y.cpu().data.numpy()\n",
        "        #print(y.shape)\n",
        "        #print(prediction.shape)\n",
        "        correct = len( np.where(prediction==y)[0] )\n",
        "        \n",
        "        total_correct+=correct\n",
        "        total_number+=x.shape[0]\n",
        "        \n",
        "    return total_correct/float(total_number)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xEMZhJcFEt8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "02e5467f-9c6d-487b-ccee-4f56e9771f29"
      },
      "source": [
        "test_ds = CustomDataset('/content/Data/valid_ds.h5')\n",
        "batch_size = 120\n",
        "batch_sampler_test_ds = CustomBatchSampler(test_ds.n_points, batch_size)\n",
        "data_loader_test = DataLoader(test_ds, batch_sampler=batch_sampler_test_ds)\n",
        "\n",
        "compute_accuracy(data_loader_test,net)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncBycGjtFEt-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "faff153761aa45b98c57edcbb064d952",
            "87c8999381e547d7b5c9a22cde2296a4",
            "e02a36c05e1b4b61a0e189a0faa3f85b",
            "a945f37ce4e747f08cc1760900e9b84b",
            "2c87614bab5d400fab17afa8c8426f7a",
            "61040063c7714eafa010126ee86ab2dd",
            "be797968e2ee4d0093e837eb4737273b",
            "c05c1c3fd3a44d24ae2b3579f18d36e8"
          ]
        },
        "outputId": "69c83302-b7a8-4dd3-868e-71a16fa3a041"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "n_epochs = 25\n",
        "\n",
        "\n",
        "loss_vs_epoch = []\n",
        "accuracy_vs_epoch = []\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "  training_loss = 0\n",
        "  validation_loss =0\n",
        "  training_accuracy = 0\n",
        "  validation_accuracy = 0\n",
        "  net.train()\n",
        "  for x,y in train_data_loader:\n",
        "      if torch.cuda.is_available():\n",
        "        x,y = x.cuda(),y.cuda()\n",
        "      #clear the grade of all optimzed variables \n",
        "      optimizer.zero_grad()\n",
        "      output = net(x)\n",
        "      #print(y)\n",
        "      #print(output)\n",
        "      #calculate the loss \n",
        "      loss = loss_func(output,y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      training_loss += loss.item() * x.size(0)\n",
        "\n",
        "  net.eval()\n",
        "  for x,y in data_loader_test:\n",
        "      if torch.cuda.is_available():\n",
        "        x,y = x.cuda(),y.cuda()\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = net(x)   # calculate the loss\n",
        "      loss = loss_func(output,y) # update running validation loss \n",
        "      validation_loss += loss.item() * x.size(0)\n",
        "      \n",
        "  training_accuracy = compute_accuracy(train_data_loader,net)\n",
        "  validation_accuracy = compute_accuracy(data_loader_test,net)\n",
        "  loss_vs_epoch.append([training_loss/len(ds), validation_loss/len(test_ds)])\n",
        "  accuracy_vs_epoch.append([training_accuracy,validation_accuracy])\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "faff153761aa45b98c57edcbb064d952",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2329, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.7451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.7781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.7938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.7079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.6256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1058, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7b02995447be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mvalidation_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m   \u001b[0mloss_vs_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0maccuracy_vs_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_accuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-ca6a847a548d>\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(data_loader, net)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-675ba00c52f7>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2132\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index by location index with a non-integer key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71rdrFhsFEuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_vs_epoch = np.array(loss_vs_epoch)\n",
        "\n",
        "plt.plot(loss_vs_epoch[:,0][1:],label='training loss')\n",
        "plt.plot(loss_vs_epoch[:,1][1:],label='validation loss')\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY0hqYE82M9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_vs_epoch = np.array(accuracy_vs_epoch)\n",
        "\n",
        "plt.plot(accuracy_vs_epoch[:,0][1:],label='training accuracy')\n",
        "plt.plot(accuracy_vs_epoch[:,1][1:],label='validation accuracy')\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TLJGMd_2QQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(net.state_dict(), '/content/model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}