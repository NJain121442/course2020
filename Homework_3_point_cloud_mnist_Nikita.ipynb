{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Homework_3_point_cloud_mnist.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "539f2806a2ec4185acb6eccf3ee957ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1e729135c494b1a861ca2726c2b4496",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0b67e0e625b6420daadc2c755a7b7a25",
              "IPY_MODEL_ccd1214df9b24ba8b219314020439ed7"
            ]
          }
        },
        "d1e729135c494b1a861ca2726c2b4496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b67e0e625b6420daadc2c755a7b7a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_07e7b4a5c5b94575a3f780de5538803c",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7349b8397fdc4f6a853cb7b2c38f8d64"
          }
        },
        "ccd1214df9b24ba8b219314020439ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d6f4229f69714bdb9ff928e57598a5da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/50 [00:36&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55ceab9115534236bfac82f6a54115fe"
          }
        },
        "07e7b4a5c5b94575a3f780de5538803c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7349b8397fdc4f6a853cb7b2c38f8d64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6f4229f69714bdb9ff928e57598a5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55ceab9115534236bfac82f6a54115fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NJain121442/course2020/blob/master/Homework_3_point_cloud_mnist_Nikita.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9eac0TWJB_U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "52127b87-2990-46c2-defa-c77d55bbec2c"
      },
      "source": [
        "pip install tables --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tables\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.7.1)\n",
            "Installing collected packages: tables\n",
            "  Found existing installation: tables 3.4.4\n",
            "    Uninstalling tables-3.4.4:\n",
            "      Successfully uninstalled tables-3.4.4\n",
            "Successfully installed tables-3.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjlx5CdzFEsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83To5-lzFlrc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "dd9f5036-91b8-48f4-f4af-a70ac8fc5ed6"
      },
      "source": [
        "!wget -O  Data.zip https://www.dropbox.com/sh/h7wj4owo5vxwzgp/AACdZ5vjsHRv6utQk0_ZtIH4a?dl=0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-22 21:12:02--  https://www.dropbox.com/sh/h7wj4owo5vxwzgp/AACdZ5vjsHRv6utQk0_ZtIH4a?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.1, 2620:100:601d:1::a27d:501\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/raw/h7wj4owo5vxwzgp/AACdZ5vjsHRv6utQk0_ZtIH4a [following]\n",
            "--2020-06-22 21:12:02--  https://www.dropbox.com/sh/raw/h7wj4owo5vxwzgp/AACdZ5vjsHRv6utQk0_ZtIH4a\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc8176d96b8df2fd30bf53c81d1.dl.dropboxusercontent.com/zip_download_get/Adgoo3ctn-JfIa8COtBrdOlvc0XffaJvyPo8c1sp0Q3dbQfXkfaNDzreCYg3uF7s6U3Dlqvy6mkweqBcjuaWouDI03o39uhwjne6DWoxiM4ItA [following]\n",
            "--2020-06-22 21:12:03--  https://ucc8176d96b8df2fd30bf53c81d1.dl.dropboxusercontent.com/zip_download_get/Adgoo3ctn-JfIa8COtBrdOlvc0XffaJvyPo8c1sp0Q3dbQfXkfaNDzreCYg3uF7s6U3Dlqvy6mkweqBcjuaWouDI03o39uhwjne6DWoxiM4ItA\n",
            "Resolving ucc8176d96b8df2fd30bf53c81d1.dl.dropboxusercontent.com (ucc8176d96b8df2fd30bf53c81d1.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to ucc8176d96b8df2fd30bf53c81d1.dl.dropboxusercontent.com (ucc8176d96b8df2fd30bf53c81d1.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75147062 (72M) [application/zip]\n",
            "Saving to: ‘Data.zip’\n",
            "\n",
            "Data.zip            100%[===================>]  71.67M  24.0MB/s    in 3.0s    \n",
            "\n",
            "2020-06-22 21:12:07 (24.0 MB/s) - ‘Data.zip’ saved [75147062/75147062]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxnOx_tggxLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "738993ab-6530-40b3-c952-738a3e62cfb8"
      },
      "source": [
        "!unzip /content/Data.zip -d /content/Data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/Data.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            " extracting: /content/Data/valid_ds.h5  \n",
            " extracting: /content/Data/training_ds.h5  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEPp-0I1HZYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = pd.read_hdf('/content/Data/training_ds.h5')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy0iff_XFEsx",
        "colab_type": "text"
      },
      "source": [
        "# Homework 3\n",
        "## Point Cloud MNIST with DeepSet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqYpFOe2FEsy",
        "colab_type": "text"
      },
      "source": [
        "below you have a custom dataloader for the point-cloud MNIST dataset,\n",
        "\n",
        "the training and validation datasets are linked from the course website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGcolM_3FEsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        \n",
        "\n",
        "        \n",
        "        self.df = pd.read_hdf(path)\n",
        "        \n",
        "        self.label = torch.LongTensor(self.df.label)\n",
        "        \n",
        "        self.n_points = self.df.n_points\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "       \n",
        "        return len(self.label)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "    \n",
        "        return torch.FloatTensor(self.df.iloc[idx].xy), self.label[idx]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yonjFSthFEs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = CustomDataset('/content/Data/training_ds.h5')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inBZp9PLFEs9",
        "colab_type": "text"
      },
      "source": [
        "#### the data is exactly like the MNIST dataset, except that instead of a 28x28 image,\n",
        "#### you get a (N x 2) array of points (different number of points for each item in the dataset) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmsnIHA8FEs9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "ce9660aa-0cc3-4d02-d1df-b04192786978"
      },
      "source": [
        "fig,ax = plt.subplots(figsize=(5,5))\n",
        "\n",
        "xy = ds[445][0]\n",
        "\n",
        "ax.scatter( xy[:,0],xy[:,1] )\n",
        "\n",
        "ax.set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkAv1HxkFEtB",
        "colab_type": "text"
      },
      "source": [
        "### the dataset object has a n_points variable that tells us how many points in each item"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_chwDlsAFEtC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "365b12b7-6ee6-4c74-9fea-a589d6fb730b"
      },
      "source": [
        "ds.n_points"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       117\n",
              "1       130\n",
              "2        88\n",
              "3        70\n",
              "4        97\n",
              "       ... \n",
              "9995    120\n",
              "9996    111\n",
              "9997    114\n",
              "9998     81\n",
              "9999     88\n",
              "Name: n_points, Length: 10000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiFbrnWEFEtF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "70a46755-79b2-4dbb-f313-de48968de94d"
      },
      "source": [
        "plt.hist(ds.n_points,np.linspace(19.5,260.5,242))\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5lmzvzwFEtM",
        "colab_type": "text"
      },
      "source": [
        "## One way to deal with this variable size is to use a custom Batch Sampler\n",
        "\n",
        "https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "This object will tell our dataloader which item indices to request for the batches - \n",
        "and we can \"rig\" it to return batches where all the items have the same N, and therefore we can stack them without a custom colate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JalLewdIFEtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomBatchSampler(Sampler):\n",
        "    def __init__(self, points_per_entry, batch_size):\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        self.N_per_entry = points_per_entry\n",
        "        self.batches = {}\n",
        "        \n",
        "    def generate_batches(self):\n",
        "        \n",
        "        self.entries_with_N = {}\n",
        "        running_idx = -1\n",
        "\n",
        "        for N in set(self.N_per_entry):\n",
        "            \n",
        "            self.entries_with_N[N] = np.where(self.N_per_entry == N)[0]\n",
        "\n",
        "            how_many = len(self.entries_with_N[N])\n",
        "            n_batches = np.amax([ how_many / self.batch_size, 1])\n",
        "\n",
        "            self.entries_with_N[N] = np.array_split(np.random.permutation(self.entries_with_N[N]),\n",
        "                                                           n_batches)\n",
        "            for batch in self.entries_with_N[N]:\n",
        "                running_idx += 1\n",
        "                self.batches[running_idx] = batch\n",
        "\n",
        "        self.n_batches = running_idx + 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_batches\n",
        "\n",
        "    def __iter__(self):\n",
        "        \n",
        "        self.generate_batches()\n",
        "        \n",
        "        batch_order = np.random.permutation(np.arange(self.n_batches))\n",
        "        for i in batch_order:\n",
        "            yield self.batches[i]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRAai43WFEtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 120\n",
        "batch_sampler = CustomBatchSampler(ds.n_points, batch_size)\n",
        "train_data_loader = DataLoader(ds, batch_sampler=batch_sampler)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmthJHPOFEtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30296bf3-ff58-42f4-8329-cb40cdcc3e81"
      },
      "source": [
        "for epoch in range(3):\n",
        "    for x,y in train_data_loader:\n",
        "        print(x.shape)\n",
        "        print(x.size(0))\n",
        "        print(y.shape)\n",
        "    break"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([14, 182, 2])\n",
            "14\n",
            "torch.Size([14])\n",
            "torch.Size([105, 118, 2])\n",
            "105\n",
            "torch.Size([105])\n",
            "torch.Size([4, 208, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([66, 142, 2])\n",
            "66\n",
            "torch.Size([66])\n",
            "torch.Size([1, 241, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([33, 170, 2])\n",
            "33\n",
            "torch.Size([33])\n",
            "torch.Size([106, 111, 2])\n",
            "106\n",
            "torch.Size([106])\n",
            "torch.Size([12, 181, 2])\n",
            "12\n",
            "torch.Size([12])\n",
            "torch.Size([80, 72, 2])\n",
            "80\n",
            "torch.Size([80])\n",
            "torch.Size([94, 84, 2])\n",
            "94\n",
            "torch.Size([94])\n",
            "torch.Size([2, 239, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([104, 78, 2])\n",
            "104\n",
            "torch.Size([104])\n",
            "torch.Size([73, 67, 2])\n",
            "73\n",
            "torch.Size([73])\n",
            "torch.Size([12, 189, 2])\n",
            "12\n",
            "torch.Size([12])\n",
            "torch.Size([26, 51, 2])\n",
            "26\n",
            "torch.Size([26])\n",
            "torch.Size([3, 233, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([78, 132, 2])\n",
            "78\n",
            "torch.Size([78])\n",
            "torch.Size([37, 171, 2])\n",
            "37\n",
            "torch.Size([37])\n",
            "torch.Size([75, 136, 2])\n",
            "75\n",
            "torch.Size([75])\n",
            "torch.Size([3, 221, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([1, 25, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([81, 125, 2])\n",
            "81\n",
            "torch.Size([81])\n",
            "torch.Size([1, 242, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([126, 104, 2])\n",
            "126\n",
            "torch.Size([126])\n",
            "torch.Size([4, 218, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([13, 39, 2])\n",
            "13\n",
            "torch.Size([13])\n",
            "torch.Size([73, 73, 2])\n",
            "73\n",
            "torch.Size([73])\n",
            "torch.Size([30, 53, 2])\n",
            "30\n",
            "torch.Size([30])\n",
            "torch.Size([14, 184, 2])\n",
            "14\n",
            "torch.Size([14])\n",
            "torch.Size([53, 60, 2])\n",
            "53\n",
            "torch.Size([53])\n",
            "torch.Size([45, 65, 2])\n",
            "45\n",
            "torch.Size([45])\n",
            "torch.Size([46, 63, 2])\n",
            "46\n",
            "torch.Size([46])\n",
            "torch.Size([42, 61, 2])\n",
            "42\n",
            "torch.Size([42])\n",
            "torch.Size([4, 215, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([78, 71, 2])\n",
            "78\n",
            "torch.Size([78])\n",
            "torch.Size([41, 159, 2])\n",
            "41\n",
            "torch.Size([41])\n",
            "torch.Size([11, 197, 2])\n",
            "11\n",
            "torch.Size([11])\n",
            "torch.Size([63, 147, 2])\n",
            "63\n",
            "torch.Size([63])\n",
            "torch.Size([8, 196, 2])\n",
            "8\n",
            "torch.Size([8])\n",
            "torch.Size([30, 168, 2])\n",
            "30\n",
            "torch.Size([30])\n",
            "torch.Size([16, 190, 2])\n",
            "16\n",
            "torch.Size([16])\n",
            "torch.Size([8, 194, 2])\n",
            "8\n",
            "torch.Size([8])\n",
            "torch.Size([50, 156, 2])\n",
            "50\n",
            "torch.Size([50])\n",
            "torch.Size([96, 103, 2])\n",
            "96\n",
            "torch.Size([96])\n",
            "torch.Size([98, 97, 2])\n",
            "98\n",
            "torch.Size([98])\n",
            "torch.Size([90, 127, 2])\n",
            "90\n",
            "torch.Size([90])\n",
            "torch.Size([108, 96, 2])\n",
            "108\n",
            "torch.Size([108])\n",
            "torch.Size([84, 76, 2])\n",
            "84\n",
            "torch.Size([84])\n",
            "torch.Size([1, 247, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([1, 225, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([15, 187, 2])\n",
            "15\n",
            "torch.Size([15])\n",
            "torch.Size([115, 110, 2])\n",
            "115\n",
            "torch.Size([115])\n",
            "torch.Size([21, 47, 2])\n",
            "21\n",
            "torch.Size([21])\n",
            "torch.Size([9, 198, 2])\n",
            "9\n",
            "torch.Size([9])\n",
            "torch.Size([86, 128, 2])\n",
            "86\n",
            "torch.Size([86])\n",
            "torch.Size([36, 158, 2])\n",
            "36\n",
            "torch.Size([36])\n",
            "torch.Size([8, 195, 2])\n",
            "8\n",
            "torch.Size([8])\n",
            "torch.Size([2, 31, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([4, 213, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([77, 98, 2])\n",
            "77\n",
            "torch.Size([77])\n",
            "torch.Size([54, 64, 2])\n",
            "54\n",
            "torch.Size([54])\n",
            "torch.Size([17, 186, 2])\n",
            "17\n",
            "torch.Size([17])\n",
            "torch.Size([18, 191, 2])\n",
            "18\n",
            "torch.Size([18])\n",
            "torch.Size([66, 70, 2])\n",
            "66\n",
            "torch.Size([66])\n",
            "torch.Size([4, 202, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([21, 179, 2])\n",
            "21\n",
            "torch.Size([21])\n",
            "torch.Size([3, 227, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([4, 212, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([111, 112, 2])\n",
            "111\n",
            "torch.Size([111])\n",
            "torch.Size([110, 90, 2])\n",
            "110\n",
            "torch.Size([110])\n",
            "torch.Size([125, 107, 2])\n",
            "125\n",
            "torch.Size([125])\n",
            "torch.Size([5, 203, 2])\n",
            "5\n",
            "torch.Size([5])\n",
            "torch.Size([3, 28, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([75, 69, 2])\n",
            "75\n",
            "torch.Size([75])\n",
            "torch.Size([27, 165, 2])\n",
            "27\n",
            "torch.Size([27])\n",
            "torch.Size([30, 167, 2])\n",
            "30\n",
            "torch.Size([30])\n",
            "torch.Size([31, 52, 2])\n",
            "31\n",
            "torch.Size([31])\n",
            "torch.Size([104, 123, 2])\n",
            "104\n",
            "torch.Size([104])\n",
            "torch.Size([18, 188, 2])\n",
            "18\n",
            "torch.Size([18])\n",
            "torch.Size([49, 157, 2])\n",
            "49\n",
            "torch.Size([49])\n",
            "torch.Size([6, 205, 2])\n",
            "6\n",
            "torch.Size([6])\n",
            "torch.Size([81, 122, 2])\n",
            "81\n",
            "torch.Size([81])\n",
            "torch.Size([53, 139, 2])\n",
            "53\n",
            "torch.Size([53])\n",
            "torch.Size([116, 100, 2])\n",
            "116\n",
            "torch.Size([116])\n",
            "torch.Size([58, 152, 2])\n",
            "58\n",
            "torch.Size([58])\n",
            "torch.Size([110, 88, 2])\n",
            "110\n",
            "torch.Size([110])\n",
            "torch.Size([35, 164, 2])\n",
            "35\n",
            "torch.Size([35])\n",
            "torch.Size([59, 141, 2])\n",
            "59\n",
            "torch.Size([59])\n",
            "torch.Size([95, 130, 2])\n",
            "95\n",
            "torch.Size([95])\n",
            "torch.Size([63, 68, 2])\n",
            "63\n",
            "torch.Size([63])\n",
            "torch.Size([25, 172, 2])\n",
            "25\n",
            "torch.Size([25])\n",
            "torch.Size([4, 206, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([106, 99, 2])\n",
            "106\n",
            "torch.Size([106])\n",
            "torch.Size([20, 174, 2])\n",
            "20\n",
            "torch.Size([20])\n",
            "torch.Size([23, 48, 2])\n",
            "23\n",
            "torch.Size([23])\n",
            "torch.Size([35, 163, 2])\n",
            "35\n",
            "torch.Size([35])\n",
            "torch.Size([53, 151, 2])\n",
            "53\n",
            "torch.Size([53])\n",
            "torch.Size([75, 66, 2])\n",
            "75\n",
            "torch.Size([75])\n",
            "torch.Size([72, 143, 2])\n",
            "72\n",
            "torch.Size([72])\n",
            "torch.Size([81, 75, 2])\n",
            "81\n",
            "torch.Size([81])\n",
            "torch.Size([67, 137, 2])\n",
            "67\n",
            "torch.Size([67])\n",
            "torch.Size([62, 146, 2])\n",
            "62\n",
            "torch.Size([62])\n",
            "torch.Size([2, 207, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([33, 162, 2])\n",
            "33\n",
            "torch.Size([33])\n",
            "torch.Size([116, 95, 2])\n",
            "116\n",
            "torch.Size([116])\n",
            "torch.Size([3, 210, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([55, 154, 2])\n",
            "55\n",
            "torch.Size([55])\n",
            "torch.Size([108, 91, 2])\n",
            "108\n",
            "torch.Size([108])\n",
            "torch.Size([35, 169, 2])\n",
            "35\n",
            "torch.Size([35])\n",
            "torch.Size([102, 121, 2])\n",
            "102\n",
            "torch.Size([102])\n",
            "torch.Size([1, 243, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([19, 185, 2])\n",
            "19\n",
            "torch.Size([19])\n",
            "torch.Size([4, 204, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([1, 29, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([12, 200, 2])\n",
            "12\n",
            "torch.Size([12])\n",
            "torch.Size([64, 145, 2])\n",
            "64\n",
            "torch.Size([64])\n",
            "torch.Size([98, 92, 2])\n",
            "98\n",
            "torch.Size([98])\n",
            "torch.Size([107, 94, 2])\n",
            "107\n",
            "torch.Size([107])\n",
            "torch.Size([92, 126, 2])\n",
            "92\n",
            "torch.Size([92])\n",
            "torch.Size([68, 62, 2])\n",
            "68\n",
            "torch.Size([68])\n",
            "torch.Size([3, 219, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([92, 120, 2])\n",
            "92\n",
            "torch.Size([92])\n",
            "torch.Size([3, 35, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([60, 138, 2])\n",
            "60\n",
            "torch.Size([60])\n",
            "torch.Size([127, 109, 2])\n",
            "127\n",
            "torch.Size([127])\n",
            "torch.Size([96, 89, 2])\n",
            "96\n",
            "torch.Size([96])\n",
            "torch.Size([29, 54, 2])\n",
            "29\n",
            "torch.Size([29])\n",
            "torch.Size([102, 77, 2])\n",
            "102\n",
            "torch.Size([102])\n",
            "torch.Size([82, 129, 2])\n",
            "82\n",
            "torch.Size([82])\n",
            "torch.Size([3, 33, 2])\n",
            "3\n",
            "torch.Size([3])\n",
            "torch.Size([53, 150, 2])\n",
            "53\n",
            "torch.Size([53])\n",
            "torch.Size([1, 30, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([33, 55, 2])\n",
            "33\n",
            "torch.Size([33])\n",
            "torch.Size([55, 153, 2])\n",
            "55\n",
            "torch.Size([55])\n",
            "torch.Size([11, 183, 2])\n",
            "11\n",
            "torch.Size([11])\n",
            "torch.Size([5, 209, 2])\n",
            "5\n",
            "torch.Size([5])\n",
            "torch.Size([118, 106, 2])\n",
            "118\n",
            "torch.Size([118])\n",
            "torch.Size([1, 226, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([92, 134, 2])\n",
            "92\n",
            "torch.Size([92])\n",
            "torch.Size([4, 217, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([5, 214, 2])\n",
            "5\n",
            "torch.Size([5])\n",
            "torch.Size([6, 193, 2])\n",
            "6\n",
            "torch.Size([6])\n",
            "torch.Size([81, 82, 2])\n",
            "81\n",
            "torch.Size([81])\n",
            "torch.Size([16, 40, 2])\n",
            "16\n",
            "torch.Size([16])\n",
            "torch.Size([7, 220, 2])\n",
            "7\n",
            "torch.Size([7])\n",
            "torch.Size([96, 81, 2])\n",
            "96\n",
            "torch.Size([96])\n",
            "torch.Size([49, 149, 2])\n",
            "49\n",
            "torch.Size([49])\n",
            "torch.Size([47, 135, 2])\n",
            "47\n",
            "torch.Size([47])\n",
            "torch.Size([82, 83, 2])\n",
            "82\n",
            "torch.Size([82])\n",
            "torch.Size([40, 59, 2])\n",
            "40\n",
            "torch.Size([40])\n",
            "torch.Size([2, 211, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([23, 178, 2])\n",
            "23\n",
            "torch.Size([23])\n",
            "torch.Size([25, 46, 2])\n",
            "25\n",
            "torch.Size([25])\n",
            "torch.Size([4, 37, 2])\n",
            "4\n",
            "torch.Size([4])\n",
            "torch.Size([28, 177, 2])\n",
            "28\n",
            "torch.Size([28])\n",
            "torch.Size([98, 115, 2])\n",
            "98\n",
            "torch.Size([98])\n",
            "torch.Size([7, 34, 2])\n",
            "7\n",
            "torch.Size([7])\n",
            "torch.Size([89, 114, 2])\n",
            "89\n",
            "torch.Size([89])\n",
            "torch.Size([16, 44, 2])\n",
            "16\n",
            "torch.Size([16])\n",
            "torch.Size([90, 80, 2])\n",
            "90\n",
            "torch.Size([90])\n",
            "torch.Size([118, 102, 2])\n",
            "118\n",
            "torch.Size([118])\n",
            "torch.Size([2, 245, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([76, 133, 2])\n",
            "76\n",
            "torch.Size([76])\n",
            "torch.Size([36, 160, 2])\n",
            "36\n",
            "torch.Size([36])\n",
            "torch.Size([104, 119, 2])\n",
            "104\n",
            "torch.Size([104])\n",
            "torch.Size([71, 148, 2])\n",
            "71\n",
            "torch.Size([71])\n",
            "torch.Size([28, 50, 2])\n",
            "28\n",
            "torch.Size([28])\n",
            "torch.Size([5, 36, 2])\n",
            "5\n",
            "torch.Size([5])\n",
            "torch.Size([2, 223, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([23, 45, 2])\n",
            "23\n",
            "torch.Size([23])\n",
            "torch.Size([1, 236, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([45, 56, 2])\n",
            "45\n",
            "torch.Size([45])\n",
            "torch.Size([8, 41, 2])\n",
            "8\n",
            "torch.Size([8])\n",
            "torch.Size([114, 108, 2])\n",
            "114\n",
            "torch.Size([114])\n",
            "torch.Size([114, 116, 2])\n",
            "114\n",
            "torch.Size([114])\n",
            "torch.Size([97, 79, 2])\n",
            "97\n",
            "torch.Size([97])\n",
            "torch.Size([1, 230, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([2, 216, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([8, 199, 2])\n",
            "8\n",
            "torch.Size([8])\n",
            "torch.Size([39, 58, 2])\n",
            "39\n",
            "torch.Size([39])\n",
            "torch.Size([102, 87, 2])\n",
            "102\n",
            "torch.Size([102])\n",
            "torch.Size([105, 105, 2])\n",
            "105\n",
            "torch.Size([105])\n",
            "torch.Size([24, 180, 2])\n",
            "24\n",
            "torch.Size([24])\n",
            "torch.Size([48, 155, 2])\n",
            "48\n",
            "torch.Size([48])\n",
            "torch.Size([19, 42, 2])\n",
            "19\n",
            "torch.Size([19])\n",
            "torch.Size([93, 85, 2])\n",
            "93\n",
            "torch.Size([93])\n",
            "torch.Size([1, 280, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([55, 144, 2])\n",
            "55\n",
            "torch.Size([55])\n",
            "torch.Size([1, 228, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([35, 57, 2])\n",
            "35\n",
            "torch.Size([35])\n",
            "torch.Size([100, 117, 2])\n",
            "100\n",
            "torch.Size([100])\n",
            "torch.Size([1, 26, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([115, 101, 2])\n",
            "115\n",
            "torch.Size([115])\n",
            "torch.Size([7, 201, 2])\n",
            "7\n",
            "torch.Size([7])\n",
            "torch.Size([30, 175, 2])\n",
            "30\n",
            "torch.Size([30])\n",
            "torch.Size([39, 166, 2])\n",
            "39\n",
            "torch.Size([39])\n",
            "torch.Size([8, 38, 2])\n",
            "8\n",
            "torch.Size([8])\n",
            "torch.Size([29, 49, 2])\n",
            "29\n",
            "torch.Size([29])\n",
            "torch.Size([2, 27, 2])\n",
            "2\n",
            "torch.Size([2])\n",
            "torch.Size([12, 43, 2])\n",
            "12\n",
            "torch.Size([12])\n",
            "torch.Size([84, 131, 2])\n",
            "84\n",
            "torch.Size([84])\n",
            "torch.Size([1, 234, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([10, 192, 2])\n",
            "10\n",
            "torch.Size([10])\n",
            "torch.Size([36, 161, 2])\n",
            "36\n",
            "torch.Size([36])\n",
            "torch.Size([84, 74, 2])\n",
            "84\n",
            "torch.Size([84])\n",
            "torch.Size([112, 113, 2])\n",
            "112\n",
            "torch.Size([112])\n",
            "torch.Size([78, 140, 2])\n",
            "78\n",
            "torch.Size([78])\n",
            "torch.Size([23, 176, 2])\n",
            "23\n",
            "torch.Size([23])\n",
            "torch.Size([1, 249, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([108, 124, 2])\n",
            "108\n",
            "torch.Size([108])\n",
            "torch.Size([103, 93, 2])\n",
            "103\n",
            "torch.Size([103])\n",
            "torch.Size([27, 173, 2])\n",
            "27\n",
            "torch.Size([27])\n",
            "torch.Size([1, 229, 2])\n",
            "1\n",
            "torch.Size([1])\n",
            "torch.Size([120, 86, 2])\n",
            "120\n",
            "torch.Size([120])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH9V8XKXFEtV",
        "colab_type": "text"
      },
      "source": [
        "## Building a DeepSet model\n",
        "\n",
        "you only have three components - a fully connected network that creates the node embedding, a sum operation, and a classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYPp1NTyFEtV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f20074c-506a-4a57-fa61-268862170b07"
      },
      "source": [
        "# the linear layer operates on the last dimension:\n",
        "\n",
        "linear_layer = nn.Linear(10,5)\n",
        "\n",
        "linear_layer(  torch.rand((345,10)) ).shape, linear_layer(  torch.rand((345,76,10)) ).shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([345, 5]), torch.Size([345, 76, 5]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NrQjHLVFEtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "850e4239-3dd0-4226-b235-1456afe09e80"
      },
      "source": [
        "# for the the mean operation you need to specify the dimension:\n",
        "\n",
        "x = torch.rand((42,15,10))\n",
        "\n",
        "torch.mean(x,dim=1).shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([42, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV1Q7Y5FFEtf",
        "colab_type": "text"
      },
      "source": [
        "## build the model, train, submit when you reach above 75% accuracy on the validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecZ_l1gcFEtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepSet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepSet, self).__init__()\n",
        "        self.linear_embedding1 = nn.Linear(2,16)\n",
        "        self.linear_embedding2 = nn.Linear(16,64)\n",
        "        self.linear_embedding3 = nn.Linear(64,128)\n",
        "        self.linear1 = nn.Linear(128,32)\n",
        "        self.linear2 = nn.Linear(32,10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear_embedding1(x))\n",
        "        x = F.relu(self.linear_embedding2(x))\n",
        "        x = F.relu(self.linear_embedding3(x))\n",
        "        x = torch.mean(x,1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYn1B_DoFEti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = DeepSet()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oXUu5RbFEtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.cuda\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iuXfbolFEtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4uTIu00FEtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyZRYcivFEt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(data_loader,net):\n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    total_number = 0\n",
        "    total_correct = 0\n",
        "    \n",
        "    for x,y in data_loader:\n",
        "        if torch.cuda.is_available():\n",
        "          x,y = x.cuda(),y.cuda()\n",
        "        \n",
        "        prediction = net(x).cpu().data.numpy()\n",
        "        prediction = np.argmax(prediction,axis=1)\n",
        "        y = y.cpu().data.numpy()\n",
        "        #print(y.shape)\n",
        "        #print(prediction.shape)\n",
        "        correct = len( np.where(prediction==y)[0] )\n",
        "        \n",
        "        total_correct+=correct\n",
        "        total_number+=x.shape[0]\n",
        "        \n",
        "    return total_correct/float(total_number)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xEMZhJcFEt8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2cd02c56-88f5-4fb5-ab72-dc2fa07137d6"
      },
      "source": [
        "test_ds = CustomDataset('/content/Data/valid_ds.h5')\n",
        "batch_size = 120\n",
        "batch_sampler_test_ds = CustomBatchSampler(test_ds.n_points, batch_size)\n",
        "data_loader_test = DataLoader(test_ds, batch_sampler=batch_sampler_test_ds)\n",
        "\n",
        "compute_accuracy(data_loader_test,net)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0982"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncBycGjtFEt-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "539f2806a2ec4185acb6eccf3ee957ba",
            "d1e729135c494b1a861ca2726c2b4496",
            "0b67e0e625b6420daadc2c755a7b7a25",
            "ccd1214df9b24ba8b219314020439ed7",
            "07e7b4a5c5b94575a3f780de5538803c",
            "7349b8397fdc4f6a853cb7b2c38f8d64",
            "d6f4229f69714bdb9ff928e57598a5da",
            "55ceab9115534236bfac82f6a54115fe"
          ]
        },
        "outputId": "f4e0f2db-7a6c-4152-937f-0d39e2b9bb90"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "n_epochs = 50\n",
        "\n",
        "\n",
        "loss_vs_epoch = []\n",
        "accuracy_vs_epoch = []\n",
        "for epoch in tqdm( range(n_epochs) ):\n",
        "  training_loss = 0\n",
        "  validation_loss =0\n",
        "  training_accuracy = 0\n",
        "  validation_accuracy = 0\n",
        "  net.train()\n",
        "  for x,y in train_data_loader:\n",
        "    if torch.cuda.is_available():\n",
        "      x,y = x.cuda(),y.cuda()\n",
        "      #clear the grade of all optimzed variables \n",
        "      optimizer.zero_grad()\n",
        "      output = net(x)\n",
        "      #print(y)\n",
        "      #print(output)\n",
        "      #calculate the loss \n",
        "      loss = loss_func(output,y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      training_loss += loss.item() * x.size(0)\n",
        "      \n",
        "      #print(x.size(0))\n",
        "      #print(training_loss)\n",
        "      accuracy = compute_accuracy(train_data_loader,net)\n",
        "      training_accuracy += accuracy\n",
        "    \n",
        "  net.eval()\n",
        "  for x,y in data_loader_test:\n",
        "    if torch.cuda.is_available():\n",
        "      x,y = x.cuda(),y.cuda()\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = net(x)   # calculate the loss\n",
        "      loss = loss_func(output,y) # update running validation loss \n",
        "      validation_loss += loss.item() * x.size(0)\n",
        "      accuracy = compute_accuracy(data_loader_test,net)\n",
        "      validation_accuracy += accuracy\n",
        "\n",
        "  loss_vs_epoch.append([training_loss/len(ds), validation_loss/len(test_ds)])\n",
        "  accuracy_vs_epoch.append([(training_accuracy/len(train_data_loader))*100,(validation_accuracy/len(data_loader_test))*100])\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "539f2806a2ec4185acb6eccf3ee957ba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "97\n",
            "224.9121959209442\n",
            "8\n",
            "242.59594988822937\n",
            "75\n",
            "414.2568440437317\n",
            "12\n",
            "440.96488523483276\n",
            "16\n",
            "476.1010203361511\n",
            "8\n",
            "493.47538137435913\n",
            "75\n",
            "668.1749680042267\n",
            "33\n",
            "742.8134570121765\n",
            "23\n",
            "792.663215637207\n",
            "3\n",
            "799.1134805679321\n",
            "84\n",
            "991.651819229126\n",
            "3\n",
            "998.3138763904572\n",
            "2\n",
            "1002.486251115799\n",
            "41\n",
            "1095.3099455833435\n",
            "93\n",
            "1312.0856812000275\n",
            "23\n",
            "1364.1597142219543\n",
            "112\n",
            "1625.7863430976868\n",
            "19\n",
            "1666.7949340343475\n",
            "1\n",
            "1668.8631188869476\n",
            "24\n",
            "1722.4436528682709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2a396989864d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-ca6a847a548d>\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(data_loader, net)\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-c6f9361083f7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_embedding1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_embedding2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_embedding3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71rdrFhsFEuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_vs_epoch = np.array(loss_vs_epoch)\n",
        "\n",
        "plt.plot(loss_vs_epoch[:,0][1:],label='training loss')\n",
        "plt.plot(loss_vs_epoch[:,1][1:],label='validation loss')\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY0hqYE82M9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_vs_epoch = np.array(accuracy_vs_epoch)\n",
        "\n",
        "plt.plot(accuracy_vs_epoch[:,0][1:],label='training accuracy')\n",
        "plt.plot(accuracy_vs_epoch[:,1][1:],label='validation accuracy')\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TLJGMd_2QQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(net.state_dict(), '/content/model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}